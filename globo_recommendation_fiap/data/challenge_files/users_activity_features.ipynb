{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lib Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = pd.read_parquet('local/treino.parquet')\n",
    "treino.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_multivalued_df(df: pd.DataFrame, split_columns: list) -> pd.DataFrame:\n",
    "    df[split_columns] = df[split_columns].apply(lambda col: col.str.split(','))\n",
    "    expanded_df = df.explode(split_columns, ignore_index=True)\n",
    "    return expanded_df\n",
    "\n",
    "\n",
    "def drop_columns(df: pd.DataFrame, columns_to_drop: list) -> pd.DataFrame:\n",
    "    dropped_df = df.drop(columns=columns_to_drop, axis=1)\n",
    "    return dropped_df\n",
    "\n",
    "\n",
    "def set_time_base_features(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    decay_rate = 0.0001\n",
    "    df['timestamp'] = pd.to_datetime(df['timestampHistory'], unit='ms')\n",
    "    max_date = df['timestamp'].max()\n",
    "    df['timeOnPageHistory'] = pd.to_numeric(df['timeOnPageHistory'])\n",
    "    df['days_since_click'] = (max_date - df['timestamp']).dt.days\n",
    "    df['day_of_week'] = df['timestamp'].dt.day_name()\n",
    "    df['hour_of_day'] = df['timestamp'].dt.hour\n",
    "    df['time_normalized'] = df['days_since_click'] / df['days_since_click'].max()\n",
    "    df['time_decay_weight'] = np.exp(-decay_rate * df['time_normalized'])\n",
    "    df['time_on_page_minutes'] = df['timeOnPageHistory'] / 60000\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_engagement_score(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    df['numberOfClicksHistory'] = pd.to_numeric(df['numberOfClicksHistory'])\n",
    "    df['scrollPercentageHistory'] = pd.to_numeric(df['scrollPercentageHistory'])\n",
    "    df['pageVisitsCountHistory'] = pd.to_numeric(df['pageVisitsCountHistory'])\n",
    "    df['time_on_page_minutes'] = pd.to_numeric(df['time_on_page_minutes'])\n",
    "    df['time_decay_weight'] = pd.to_numeric(df['time_decay_weight'])\n",
    "    df['engagement_score'] = (\n",
    "        df['numberOfClicksHistory'] * 0.4 +\n",
    "        df['scrollPercentageHistory'] * 0.2 +\n",
    "        df['pageVisitsCountHistory'] * 0.2 +\n",
    "        df['time_on_page_minutes'] * 0.1 +\n",
    "        df['time_decay_weight'] * 0.1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_engagement_score_with_PCA(df:pd.DataFrame, interaction_features: list) -> pd.DataFrame:\n",
    "    df['days_since_click'] = (df['days_since_click'] * -1)\n",
    "    df['time_decay_weight'] = (df['time_decay_weight'] * -1)\n",
    "    scaler = StandardScaler()\n",
    "    X = df[interaction_features]\n",
    "    scaled_X = scaler.fit_transform(X)\n",
    "    pca = PCA(n_components=1)\n",
    "    pca_result = pca.fit_transform(scaled_X)\n",
    "    df['engagement_score_pca'] = pca_result\n",
    "    return df\n",
    "\n",
    "\n",
    "def initial_adjusts(df:pd.DataFrame, )->pd.DataFrame:\n",
    "    df['userId'] = df['userId'].str.replace(r\"\\s+\", \"\", regex=True)\n",
    "    df['history'] = df['history'].str.replace(r\"\\s+\", \"\", regex=True)\n",
    "    df['timestampHistory'] = df['timestampHistory'].str.replace(r\"\\s+\", \"\", regex=True)\n",
    "    return df\n",
    "\n",
    "# I suggest mantain final adjusted column without duplicate name, only 'history' because the same pipeline could provide users.parquet file too.\n",
    "# Same observation for column timestampHistory.\n",
    "def initial_validation_adjusts(df:pd.DataFrame)->pd.DataFrame:\n",
    "    df['history'] = df['history'].str.strip()\n",
    "    df['history_adjusted'] = df['history'].str.replace(' \\n ', ',', regex=False)\n",
    "    df['history_adjusted'] = df['history_adjusted'].str.replace(r\"\\s+\", \"\", regex=True) \n",
    "    df['timestampHistory'] = df['timestampHistory'].str.strip()\n",
    "    df['timestampHistory_adjusted'] = df['timestampHistory'].str.replace(' ', ',', regex=False)\n",
    "    df['timestampHistory_adjusted'] = df['timestampHistory_adjusted'].str.replace(r\"\\s+\", \"\", regex=True) \n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_to_timestamp(df: pd.DataFrame, field: str) -> pd.DataFrame:\n",
    "    df[field] = pd.to_datetime(df[field], unit='ms')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User Pipeline Variables\n",
    "split_columns = [\n",
    "    'history', \n",
    "    'timestampHistory', \n",
    "    'numberOfClicksHistory', \n",
    "    'timeOnPageHistory', \n",
    "    'scrollPercentageHistory', \n",
    "    'pageVisitsCountHistory', \n",
    "    'timestampHistory_new'\n",
    "]\n",
    "\n",
    "columns_to_drop = [\n",
    "    'userType',\n",
    "    'historySize', \n",
    "    'timestampHistory_new', \n",
    "    'timestampHistory', \n",
    "    'timeOnPageHistory', \n",
    "    'numberOfClicksHistory', \n",
    "    'timeOnPageHistory', \n",
    "    'scrollPercentageHistory', \n",
    "    'pageVisitsCountHistory',\n",
    "    'timestamp',\n",
    "    'days_since_click',\n",
    "    'day_of_week',\n",
    "    'hour_of_day',\n",
    "    'time_normalized',\n",
    "    'time_decay_weight',\n",
    "    'time_on_page_minutes'\n",
    "]\n",
    "\n",
    "interaction_features = [\n",
    "    'numberOfClicksHistory', \n",
    "    'timeOnPageHistory', \n",
    "    'scrollPercentageHistory', \n",
    "    'pageVisitsCountHistory', \n",
    "    'time_on_page_minutes', \n",
    "    'time_decay_weight', \n",
    "    'days_since_click'\n",
    "]\n",
    "\n",
    "validation_split_columns = [\n",
    "    'history_adjusted',\n",
    "    'timestampHistory_adjusted'\n",
    "]\n",
    "\n",
    "validation_drop_columns = [\n",
    "    'timestampHistory',\n",
    "    'history'\n",
    "]\n",
    "\n",
    "validacao_time_field = 'timestampHistory_adjusted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('initial_adjustments_in_train', FunctionTransformer(initial_adjusts)),\n",
    "        ('split_multivalued_df', FunctionTransformer(\n",
    "            split_multivalued_df, \n",
    "            kw_args={'split_columns': split_columns})),\n",
    "        ('create_time_features', FunctionTransformer(set_time_base_features)),\n",
    "        ('set_engagement_score_with_pca', FunctionTransformer(\n",
    "            get_engagement_score_with_PCA, \n",
    "            kw_args={'interaction_features': interaction_features})),\n",
    "        ('set_engagement_score_with_formula', FunctionTransformer(calculate_engagement_score)),\n",
    "        ('drop_columns', FunctionTransformer(drop_columns, kw_args={'columns_to_drop': columns_to_drop}))\n",
    "    ]\n",
    ")\n",
    "\n",
    "validation_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('initial_adjustments_in_validation', FunctionTransformer(initial_validation_adjusts)),\n",
    "        ('split_multivalued_columns', FunctionTransformer(\n",
    "            split_multivalued_df,\n",
    "            kw_args={'split_columns': validation_split_columns})),\n",
    "        ('convert_timestamp_field', FunctionTransformer(\n",
    "            convert_to_timestamp,\n",
    "            kw_args={'field': validacao_time_field})),\n",
    "        ('drop_columns', FunctionTransformer(drop_columns, kw_args={'columns_to_drop': validation_drop_columns}))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pipeline = treino.head()\n",
    "users_df = users_pipeline.transform(df_test_pipeline)\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PROD Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = users_pipeline.transform(treino)\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filepath = 'local/user_colab_filter.parquet'\n",
    "users_df.to_parquet(out_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Users Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validacao = pd.read_parquet('local/validacao.parquet')\n",
    "validacao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validacao_df = validation_pipeline.transform(validacao)\n",
    "validacao_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validacao_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itens = pd.read_parquet('local/itens_text_db_scan.parquet')\n",
    "itens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strictly necessary before merge\n",
    "itens['page'] = itens['page'].str.replace(r\"\\s+\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(validacao_df, itens, how='left', left_on='history_adjusted', right_on='page')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(178868 - 112184)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df['userId'][178863])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df['history'] = users_df['history'].str.strip()\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train_df = pd.merge(users_df, itens, how='left', left_on='history', right_on='page')\n",
    "merged_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_train = merged_train_df.groupby(['userId', 'classes'])['engagement_score'].mean().reset_index()\n",
    "grouped_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = grouped_train[grouped_train['userId'] == 'aacb28d7d2a4ea745e12ceba1f9ffa0c7b92aae9304ce51f7f66044a927bdbaa']\n",
    "filtered_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_validation_df = merged_df[['userId', 'page', 'classes']][merged_df['userId'] == 'aacb28d7d2a4ea745e12ceba1f9ffa0c7b92aae9304ce51f7f66044a927bdbaa']\n",
    "filtered_validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
